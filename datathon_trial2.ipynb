{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apq3VMkTXvI9"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "\n",
        "\n",
        "def load_data(path):\n",
        "    data = pd.read_csv(path)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X50ydor7kKK0",
        "outputId": "585ef0c9-2485-4bbb-a065-ddfab4b1f3d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Hyperparameter Optimization....\n",
            "Top 3 Models:\n",
            "1. RF: 0.9544\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "\n",
        "\n",
        "def load_data(path):\n",
        "    data = pd.read_csv(path)\n",
        "    return data\n",
        "\n",
        "new_df=load_data(\"/content/drive/MyDrive/datathon/purelyData.csv\")\n",
        "y=new_df[\"Öbek İsmi\"]\n",
        "X=new_df.drop([\"Öbek İsmi\"],axis=1)\n",
        "X = X.drop(X.columns[0], axis=1)\n",
        "\n",
        "def models(X,y, scoring=\"roc_auc\"):\n",
        "  classifiers=[\n",
        "               (\"RF\", RandomForestClassifier()),\n",
        "\n",
        "\n",
        "               ]\n",
        "  for name, classifier in classifiers:\n",
        "        cv_results = cross_validate(classifier, X, y, cv=5, scoring=scoring)\n",
        "\n",
        "\n",
        "\n",
        "print(models(X,y,scoring=\"accuracy\"))\n",
        "\n",
        "\n",
        "\n",
        "rf_params = {\"max_depth\": [1, 30, None],\n",
        "\n",
        "             \"max_features\": [5, 20, \"auto\"],\n",
        "             \"min_samples_split\": [15, 40],\n",
        "             \"n_estimators\": [200, 375]}\n",
        "\n",
        "\n",
        "\n",
        "classifiers = [\n",
        "               (\"RF\", RandomForestClassifier(), rf_params)\n",
        "               ]\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "def hyperparameter_optimization(X, y, classifiers, cv=5, scoring=\"roc_auc\"):\n",
        "    # Fonksiyon kodu burada devam eder...\n",
        "\n",
        "    print(\"Hyperparameter Optimization....\")\n",
        "\n",
        "    top_models = []  # Boş bir liste en iyi modelleri saklamak için\n",
        "\n",
        "    for name, classifier, params in classifiers:\n",
        "\n",
        "        cv_results = cross_validate(classifier, X, y, cv=cv, scoring=scoring)\n",
        "\n",
        "\n",
        "        gs_best = GridSearchCV(classifier, params, cv=cv, n_jobs=-1, verbose=False).fit(X, y)\n",
        "        final_model = classifier.set_params(**gs_best.best_params_)\n",
        "\n",
        "        cv_results = cross_validate(final_model, X, y, cv=cv, scoring=scoring)\n",
        "\n",
        "\n",
        "        # Modelleri performanslarına göre sırala ve en iyi 3'ü sakla\n",
        "        top_models.append((name, final_model, cv_results['test_score'].mean()))\n",
        "        top_models.sort(key=lambda x: x[2], reverse=True)\n",
        "        top_models = top_models[:3]\n",
        "\n",
        "\n",
        "\n",
        "    return  top_models\n",
        "\n",
        "top_models = hyperparameter_optimization(X, y, classifiers, scoring=\"accuracy\")\n",
        "\n",
        "# En iyi 3 modeli yazdır\n",
        "print(\"Top 3 Models:\")\n",
        "for idx, (name, model, score) in enumerate(top_models):\n",
        "    print(f\"{idx + 1}. {name}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVP3wNW04LZH",
        "outputId": "4c7d330e-ced3-462d-d478-4abd7f457494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameter Optimization....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Models:\n",
            "1. RF: 0.9548\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "new_df=load_data(\"/content/drive/MyDrive/datathon/purelyData.csv\")\n",
        "y=new_df[\"Öbek İsmi\"]\n",
        "X=new_df.drop([\"Öbek İsmi\"],axis=1)\n",
        "X = X.drop(X.columns[0], axis=1)\n",
        "\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "rf_params = {\n",
        "    \"max_depth\": [None, 5, 10, 15],  # Include more depth options\n",
        "    \"max_features\": [\"auto\", \"sqrt\"],\n",
        "    \"min_samples_split\": [ 5, 10, 20],  # Include more split options\n",
        "    \"min_samples_leaf\": [1, 2, 4,6],  # Include more leaf options\n",
        "    \"n_estimators\": [100, 300,350] }\n",
        "\n",
        "classifiers = [(\"RF\", RandomForestClassifier(random_state=42), rf_params)]\n",
        "\n",
        "def hyperparameter_optimization(X, y, classifiers, cv=5, scoring=\"accuracy\"):\n",
        "    print(\"Hyperparameter Optimization....\")\n",
        "    top_models = []  # To store the top models\n",
        "\n",
        "    for name, classifier, params in classifiers:\n",
        "        gs = GridSearchCV(classifier, params, cv=cv, n_jobs=-1, scoring=scoring)\n",
        "        gs.fit(X, y)\n",
        "        best_model = gs.best_estimator_\n",
        "\n",
        "        cv_scores = cross_val_score(best_model, X, y, cv=cv, scoring=scoring)\n",
        "        avg_score = np.mean(cv_scores)\n",
        "\n",
        "        # Store the top models based on average CV score\n",
        "        top_models.append((name, best_model, avg_score))\n",
        "        top_models.sort(key=lambda x: x[2], reverse=True)\n",
        "        top_models = top_models[:3]\n",
        "\n",
        "    return top_models\n",
        "\n",
        "# Assuming X and y are your dataset and labels\n",
        "top_models = hyperparameter_optimization(X, y, classifiers, scoring=\"accuracy\")\n",
        "\n",
        "# Print the top 3 models\n",
        "print(\"Top 3 Models:\")\n",
        "for idx, (name, model, score) in enumerate(top_models):\n",
        "    print(f\"{idx + 1}. {name}: {score:.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eixRXnDA8x2m"
      },
      "outputs": [],
      "source": [
        "test_data=load_data(\"/content/drive/MyDrive/datathon/test.csv\")\n",
        "test_data=test_data.drop(test_data.columns[0],axis=1)\n",
        "model= top_models[0][1]\n",
        "\n",
        "predictions= model.predict(test_data)\n",
        "predictions_df = pd.DataFrame(predictions + 1, columns=[\"Öbek İsmi\"], index=test_data.index)\n",
        "predictions_df[\"Öbek İsmi\"] = \"obek_\"+predictions_df[\"Öbek İsmi\"].astype(str)\n",
        "predictions_df.index.name = \"id\"\n",
        "\n",
        "\n",
        "csv_filename = 'predictionsNew.csv'  # Kaydetmek istediğiniz dosya adını burada belirtin\n",
        "predictions_df.to_csv(csv_filename, index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}